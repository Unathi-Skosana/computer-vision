{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "\n",
    "\n",
    "from skimage import io, transform\n",
    "from skimage.util import img_as_ubyte\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, \\\n",
    "        BatchNormalization, Dense, Flatten, Activation, Input\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# TeX typesetting\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "# Aesthetics\n",
    "plt.close('all')\n",
    "plt.style.use('seaborn-pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\n",
    "    :a: numpy array\n",
    "    :returns: LaTeX bmatrix as a string\n",
    "    \"\"\"\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size  = (222, 224)\n",
    "batch_size  = 16\n",
    "num_classes = 9\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building labels and training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "classes = [\"Coast\", \"Forest\", \"Highway\", \"Kitchen\",\\\n",
    "                    \"Mountain\", \"Office\", \"Store\", \"Street\", \"Suburb\"]\n",
    "for cl in classes:\n",
    "    folder_path = os.path.join(\"../assets/assignment-6/dataset/train\", cl)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        im = io.imread(fpath)\n",
    "        im_resized = transform.resize(im, (224, 224) , anti_aliasing=True)\n",
    "        im_arr = img_to_array(im_resized)\n",
    "        train_data.append(im_arr)\n",
    "        train_labels.append(classes.index(cl))\n",
    "        \n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "hot_enc_train_labels = to_categorical(train_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "## 3 iterations - convolute, batch norm, activation and max pooling\n",
    "## flatten and output\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (2,2), input_shape=train_data.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(32, (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_200 (Conv2D)          (None, 223, 223, 16)      80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 223, 223, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 223, 223, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 54, 54, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 54, 54, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 46656)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 419913    \n",
      "=================================================================\n",
      "Total params: 430,777\n",
      "Trainable params: 430,553\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(SGD(learning_rate=0.005), loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 15s 265ms/step - loss: 12.3239 - accuracy: 0.3044\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 18s 310ms/step - loss: 4.3037 - accuracy: 0.5289\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 17s 306ms/step - loss: 1.1798 - accuracy: 0.7656\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 0.4661 - accuracy: 0.8711\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 0.2131 - accuracy: 0.9244\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 0.1938 - accuracy: 0.9311\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 0.0770 - accuracy: 0.9767\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 17s 305ms/step - loss: 0.0349 - accuracy: 0.9878\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 18s 314ms/step - loss: 0.0255 - accuracy: 0.9933\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 21s 362ms/step - loss: 0.0173 - accuracy: 0.9978\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 24s 425ms/step - loss: 0.0175 - accuracy: 0.9967\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 19s 340ms/step - loss: 0.0136 - accuracy: 0.9989\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 18s 320ms/step - loss: 0.0101 - accuracy: 0.9989\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 19s 327ms/step - loss: 0.0147 - accuracy: 0.9978\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 18s 318ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 18s 308ms/step - loss: 0.0111 - accuracy: 0.9989\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 18s 311ms/step - loss: 0.0149 - accuracy: 0.9978\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 19s 327ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 21s 372ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 21s 367ms/step - loss: 0.0073 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, hot_enc_train_labels,\n",
    "                    epochs=epochs,  \n",
    "                    batch_size=batch_size,  \n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_labels = []\n",
    "samples_per_class = [0] * num_classes\n",
    "\n",
    "for i, cl in enumerate(classes):\n",
    "    folder_path = os.path.join(\"../assets/assignment-6/dataset/test\", cl)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        im = io.imread(fpath)\n",
    "        im_resized = transform.resize(im, (224, 224) , anti_aliasing=True)\n",
    "        im_arr = img_to_array(im_resized)\n",
    "        test_data.append(im_arr)\n",
    "        test_labels.append(classes.index(cl))\n",
    "        samples_per_class[i] += 1\n",
    "        \n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "hot_enc_test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 11s 211ms/step - loss: 1.5894 - accuracy: 0.6625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.589385986328125, 0.6625368595123291]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, hot_enc_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = ImageDataGenerator(horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "## 3 iterations - convolute, batch norm, activation and max pooling\n",
    "## flatten, dropout and output\n",
    "\n",
    "sec_model = Sequential([\n",
    "    Conv2D(16, (2,2), input_shape=train_data.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(32, (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_203 (Conv2D)          (None, 223, 223, 16)      80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 223, 223, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 223, 223, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 54, 54, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 54, 54, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 46656)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 9)                 419913    \n",
      "=================================================================\n",
      "Total params: 430,777\n",
      "Trainable params: 430,553\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sec_model.compile(SGD(learning_rate=0.005), loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "sec_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 14s 251ms/step - loss: 11.9324 - accuracy: 0.3378\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 17s 305ms/step - loss: 4.1172 - accuracy: 0.5278\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 18s 317ms/step - loss: 2.6938 - accuracy: 0.6033\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 18s 310ms/step - loss: 1.5345 - accuracy: 0.7133\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 1.2084 - accuracy: 0.7378\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 18s 321ms/step - loss: 0.9366 - accuracy: 0.7978\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 18s 308ms/step - loss: 0.7311 - accuracy: 0.8244\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 18s 310ms/step - loss: 0.9985 - accuracy: 0.8267\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 17s 300ms/step - loss: 0.4445 - accuracy: 0.8833\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 18s 318ms/step - loss: 0.4795 - accuracy: 0.8611\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 0.2323 - accuracy: 0.9189\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 20s 352ms/step - loss: 0.1587 - accuracy: 0.9456\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 0.1768 - accuracy: 0.9478\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 21s 366ms/step - loss: 0.1596 - accuracy: 0.9489\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 22s 388ms/step - loss: 0.1152 - accuracy: 0.9578\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 23s 395ms/step - loss: 0.1061 - accuracy: 0.9689\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 18s 321ms/step - loss: 0.1275 - accuracy: 0.9578\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 21s 366ms/step - loss: 0.1199 - accuracy: 0.9711\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 18s 323ms/step - loss: 0.0983 - accuracy: 0.9700\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 17s 300ms/step - loss: 0.0735 - accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "sec_history = sec_model.fit(\n",
    "    data_aug.flow(train_data,\n",
    "                  hot_enc_train_labels,\n",
    "                  batch_size=batch_size\n",
    "    ),\n",
    "    epochs=epochs,  \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 8s 157ms/step - loss: 1.3865 - accuracy: 0.7245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3865114450454712, 0.7244837880134583]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_model.evaluate(test_data, hot_enc_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(model, data, labels, k = 5):\n",
    "    top = 0.0\n",
    "    probs = model.predict(data)\n",
    "    for i in range(len(labels)):\n",
    "        l = labels[i]\n",
    "        prob = probs[i]\n",
    "        top_values = (-prob).argsort()[:k] # descending order sort\n",
    "        if np.isin(np.array([l]), top_values):\n",
    "            top += 1.0\n",
    "    return probs, top / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, acc = top_k_accuracy(sec_model, test_data, test_labels, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy = 93.63 %'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"accuracy = {:.2f} %\".format(100 * acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{bmatrix}\n",
      "  187 & 2 & 44 & 9 & 8 & 8 & 0 & 0 & 2\\\\\n",
      "  4 & 187 & 0 & 4 & 15 & 3 & 10 & 5 & 0\\\\\n",
      "  10 & 4 & 114 & 15 & 2 & 4 & 2 & 7 & 2\\\\\n",
      "  0 & 0 & 0 & 82 & 0 & 16 & 8 & 1 & 3\\\\\n",
      "  33 & 27 & 28 & 28 & 125 & 16 & 3 & 12 & 2\\\\\n",
      "  0 & 0 & 0 & 12 & 0 & 103 & 0 & 0 & 0\\\\\n",
      "  0 & 3 & 0 & 21 & 0 & 10 & 162 & 11 & 8\\\\\n",
      "  0 & 2 & 2 & 10 & 1 & 7 & 12 & 153 & 5\\\\\n",
      "  0 & 0 & 2 & 10 & 0 & 5 & 5 & 4 & 115\\\\\n",
      "\\end{bmatrix}\n"
     ]
    }
   ],
   "source": [
    "print(bmatrix(confusion_matrix(test_labels,  probs.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 18441     \n",
      "=================================================================\n",
      "Total params: 21,821,225\n",
      "Trainable params: 18,441\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "57/57 [==============================] - 47s 822ms/step - loss: 2.1661 - accuracy: 0.6089\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 46s 799ms/step - loss: 0.2943 - accuracy: 0.8989\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 47s 821ms/step - loss: 0.1582 - accuracy: 0.9478\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 47s 832ms/step - loss: 0.0831 - accuracy: 0.9733\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 40s 698ms/step - loss: 0.0523 - accuracy: 0.9922\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 43s 763ms/step - loss: 0.0377 - accuracy: 0.9944\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 45s 784ms/step - loss: 0.0346 - accuracy: 0.9956\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 43s 761ms/step - loss: 0.0247 - accuracy: 0.9967\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 43s 747ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 45s 782ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 50s 875ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 44s 780ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 36s 627ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 40s 707ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 46s 810ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 46s 809ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 48s 850ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 48s 841ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 42s 741ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 40s 702ms/step - loss: 0.0087 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6673ee8760>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, pooling=\"max\", input_shape=(224,224,3))\n",
    "base_model.trainable = False\n",
    "                         \n",
    "incept_model = Sequential([\n",
    "    base_model,\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "incept_model.compile(optimizer=SGD(lr=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "incept_model.summary()\n",
    "\n",
    "preprocessed_train_data = preprocess_input(np.repeat(255. * train_data, 3, 3).astype(np.uint8))\n",
    "\n",
    "incept_model.fit(preprocessed_train_data,\n",
    "                 hot_enc_train_labels,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 77s 1s/step - loss: 0.1723 - accuracy: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1723114252090454, 0.9457226991653442]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_test_data = preprocess_input(np.repeat(255. * test_data,3,3).astype(np.uint8))\n",
    "incept_model.evaluate(preprocessed_test_data, hot_enc_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_probs, incept_acc = top_k_accuracy(incept_model, preprocessed_test_data, test_labels, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy = 99.41 %'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"accuracy = {:.2f} %\".format(100 * incept_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(627, 7), (462, 8), (816, 1), (235, 4), (105, 1)]\n",
      "2 139\n",
      "1 202\n",
      "4 58\n",
      "0 235\n",
      "0 105\n"
     ]
    }
   ],
   "source": [
    "matched = []\n",
    "while len(matched) < 5:\n",
    "    idx = np.random.randint(len(test_labels), size=1)[0]\n",
    "    prob = incept_probs[idx]\n",
    "    l = test_labels[idx]\n",
    "    c = (-prob).argsort()[0]\n",
    "    if  l != c:\n",
    "        matched.append((idx+1, c))\n",
    "        \n",
    "print(matched)\n",
    "\n",
    "for mat in matched:\n",
    "    for i in range(9):\n",
    "        if mat[0] < sum(samples_per_class[:i]):\n",
    "            print(i-1, mat[0] - sum(samples_per_class[:i-1]))\n",
    "            break;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
